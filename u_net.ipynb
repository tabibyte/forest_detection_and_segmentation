{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ajaVrH_1ahwz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "os.environ[\"PYTHONHASHSEED\"] = str(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ],
   "metadata": {
    "id": "Qj_Acrsbbo4l"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "drive_path = \"/content/drive/MyDrive\""
   ],
   "metadata": {
    "id": "yrhXUVrLnrqT"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 4\n",
    "lr = 1e-4\n",
    "epochs = 25\n",
    "height = 64\n",
    "width = 64"
   ],
   "metadata": {
    "id": "Fe26hYNwb8mI"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_path = os.path.join(drive_path,\"dataset_u-net\",\"non-aug\")\n",
    "files_dir = os.path.join(drive_path, \"Colab Notebooks\",\"files\",\"non-aug\")\n",
    "model_file = os.path.join(files_dir,\"unet-non-aug.h5\")\n",
    "log_file = os.path.join(files_dir,\"log-non-aug.csv\")"
   ],
   "metadata": {
    "id": "9eY9PFttcjz_"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_dir(path):\n",
    "  if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ],
   "metadata": {
    "id": "zovY8I7AckIP"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    " create_dir(files_dir)"
   ],
   "metadata": {
    "id": "y201EbSVeoDB"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "  x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "\n",
    "  x = Conv2D(num_filters, 3 ,padding = \"same\")(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "\n",
    "  return x"
   ],
   "metadata": {
    "id": "VBSgtXHdhCg_"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def encoder_block(inputs, num_filters):\n",
    "  x = conv_block(inputs, num_filters)\n",
    "  p = MaxPool2D((2, 2))(x)\n",
    "  return x,p"
   ],
   "metadata": {
    "id": "iPZ7Cba4iPFt"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def decoder_block(inputs, skip, num_filters):\n",
    "  x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding =\"same\")(inputs)\n",
    "  x = Concatenate()([x, skip])\n",
    "  x = conv_block(x, num_filters)\n",
    "  return x"
   ],
   "metadata": {
    "id": "1x9f_WZsibbF"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def build_unet(input_shape):\n",
    "  inputs = Input(input_shape)\n",
    "  s1,p1 = encoder_block(inputs, 64)\n",
    "  s2,p2 = encoder_block(p1, 128)\n",
    "  s3,p3 = encoder_block(p2, 256)\n",
    "  s4,p4 = encoder_block(p3, 512)\n",
    "\n",
    "  b1 = conv_block(p4, 1024)\n",
    "\n",
    "  d1 = decoder_block(b1,s4, 512)\n",
    "  d2 = decoder_block(d1,s3, 256)\n",
    "  d3 = decoder_block(d2,s2, 128)\n",
    "  d4 = decoder_block(d3,s1, 64)\n",
    "\n",
    "  outputs = Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(d4)\n",
    "\n",
    "  model = Model(inputs, outputs, name=\"UNET\")\n",
    "  return model"
   ],
   "metadata": {
    "id": "4m_TSKeKi0jY"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_data(path):\n",
    "  train_x = sorted(glob(os.path.join(path, \"train\", \"original\", \"*\")))\n",
    "  train_y = sorted(glob(os.path.join(path, \"train\", \"mask\", \"*\")))\n",
    "\n",
    "  valid_x = sorted(glob(os.path.join(path, \"validation\", \"original\", \"*\")))\n",
    "  valid_y = sorted(glob(os.path.join(path, \"validation\", \"mask\", \"*\")))\n",
    "\n",
    "  return (train_x, train_y), (valid_x, valid_y)"
   ],
   "metadata": {
    "id": "Z67E2ufGkJfd"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def read_image(path):\n",
    "  path = path.decode()\n",
    "  x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "  x = x/255.0\n",
    "  return x\n"
   ],
   "metadata": {
    "id": "ICNGJpkQlVpD"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def read_mask(path):\n",
    "  path = path.decode()\n",
    "  x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "  x = x/255.0\n",
    "  x = np.expand_dims(x, axis =-1)\n",
    "  return x\n"
   ],
   "metadata": {
    "id": "JU_BlCzanTaQ"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def tf_parse(x,y):\n",
    "  def _parse(x,y):\n",
    "    x = read_image(x)\n",
    "    y = read_mask(y)\n",
    "    return x, y\n",
    "\n",
    "  x, y = tf.numpy_function(_parse, [x,y], [tf.float64,tf.float64])\n",
    "  x.set_shape([height, width, 3])\n",
    "  y.set_shape([height, width, 1])\n",
    "\n",
    "  return x,y"
   ],
   "metadata": {
    "id": "UCkhaFfInvLm"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def tf_dataset(x,y, batch=8):\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "  dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "  dataset = dataset.batch(batch)\n",
    "  dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "  return dataset"
   ],
   "metadata": {
    "id": "mIkNpkxdpNkG"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "(train_x, train_y), (valid_x, valid_y) = load_data(dataset_path)\n",
    "print(f\"train: {len(train_x)} - {len(train_y)}\")\n",
    "print(f\"validation: {len(valid_x)} - {len(valid_y)}\")"
   ],
   "metadata": {
    "id": "IPVoUAr2puoP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "58e541e2-ac74-4100-b097-01fca1cce74b"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train: 1256 - 1256\n",
      "validation: 157 - 157\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = tf_dataset(train_x,train_y, batch=8)\n",
    "valid_dataset = tf_dataset(valid_x,valid_y, batch=8)"
   ],
   "metadata": {
    "id": "6sQK2P47y-cm"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for x,y in valid_dataset:\n",
    "  print(x.shape,y.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFSPhmvB6Cf9",
    "outputId": "d7ae5417-5410-4427-d961-db2499600e75"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(8, 64, 64, 3) (8, 64, 64, 1)\n",
      "(5, 64, 64, 3) (5, 64, 64, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_shape = (height,width,3)\n",
    "model = build_unet(input_shape)"
   ],
   "metadata": {
    "id": "55sEPg3f6YsH"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Cd5X1T47RJh",
    "outputId": "a6dbb610-a1b3-458e-fc16-34f4b1efffdf"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"UNET\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 64, 64, 64)   1792        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64, 64, 64)  256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 64, 64, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 64, 64)   36928       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 64, 64, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 32, 32, 64)   0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 128)  73856       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 128)  147584      ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 128)  0          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 16, 16, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 256)  590080      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 256)   0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 8, 8, 512)    1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 8, 8, 512)   2048        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 8, 8, 512)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 8, 8, 512)    2359808     ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 8, 8, 512)   2048        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 8, 8, 512)    0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 512)   0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 4, 4, 1024)   4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 4, 4, 1024)  4096        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 4, 4, 1024)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 4, 4, 1024)   9438208     ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 4, 4, 1024)  4096        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 4, 4, 1024)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 8, 8, 512)   2097664     ['activation_9[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 1024)   0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 8, 8, 512)    4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 8, 8, 512)    0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 512)    2359808     ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 8, 8, 512)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 16, 16, 256)  524544     ['activation_11[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 16, 16, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 256)  1179904     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 256)  590080      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 128)  131200     ['activation_13[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 32, 32, 256)  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 32, 32, 128)  295040      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 32, 32, 128)  512        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 32, 32, 128)  147584      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 32, 32, 128)  512        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 64, 64, 64)  32832       ['activation_15[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 64, 64, 128)  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 64, 64, 64)   73792       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 64, 64, 64)  256         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 64, 64, 64)  256         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 64, 64, 1)    65          ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,055,297\n",
      "Trainable params: 31,043,521\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"acc\"])"
   ],
   "metadata": {
    "id": "espXj2Eu8EtG"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(model_file, verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=4),\n",
    "    CSVLogger(log_file),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "]"
   ],
   "metadata": {
    "id": "idvExX5R8ZVZ"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Yol0RSz87Eb",
    "outputId": "0f18e382-328f-4dbf-ffe9-c444e28c0853"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.5721 - acc: 0.7664\n",
      "Epoch 1: val_loss improved from inf to 0.52318, saving model to /content/drive/MyDrive/Colab Notebooks/files/non-aug/unet-non-aug.h5\n",
      "157/157 [==============================] - 908s 6s/step - loss: 0.5721 - acc: 0.7664 - val_loss: 0.5232 - val_acc: 0.7624 - lr: 1.0000e-04\n",
      "Epoch 2/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.4014 - acc: 0.8202\n",
      "Epoch 2: val_loss improved from 0.52318 to 0.41036, saving model to /content/drive/MyDrive/Colab Notebooks/files/non-aug/unet-non-aug.h5\n",
      "157/157 [==============================] - 13s 81ms/step - loss: 0.4014 - acc: 0.8202 - val_loss: 0.4104 - val_acc: 0.8273 - lr: 1.0000e-04\n",
      "Epoch 3/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3658 - acc: 0.8341\n",
      "Epoch 3: val_loss improved from 0.41036 to 0.37059, saving model to /content/drive/MyDrive/Colab Notebooks/files/non-aug/unet-non-aug.h5\n",
      "157/157 [==============================] - 19s 122ms/step - loss: 0.3658 - acc: 0.8341 - val_loss: 0.3706 - val_acc: 0.8315 - lr: 1.0000e-04\n",
      "Epoch 4/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3402 - acc: 0.8440\n",
      "Epoch 4: val_loss improved from 0.37059 to 0.34723, saving model to /content/drive/MyDrive/Colab Notebooks/files/non-aug/unet-non-aug.h5\n",
      "157/157 [==============================] - 14s 89ms/step - loss: 0.3402 - acc: 0.8440 - val_loss: 0.3472 - val_acc: 0.8067 - lr: 1.0000e-04\n",
      "Epoch 5/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3148 - acc: 0.8557\n",
      "Epoch 5: val_loss did not improve from 0.34723\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 0.3148 - acc: 0.8557 - val_loss: 0.3561 - val_acc: 0.7841 - lr: 1.0000e-04\n",
      "Epoch 6/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2915 - acc: 0.8640\n",
      "Epoch 6: val_loss improved from 0.34723 to 0.31728, saving model to /content/drive/MyDrive/Colab Notebooks/files/non-aug/unet-non-aug.h5\n",
      "157/157 [==============================] - 13s 84ms/step - loss: 0.2915 - acc: 0.8640 - val_loss: 0.3173 - val_acc: 0.7976 - lr: 1.0000e-04\n",
      "Epoch 7/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2767 - acc: 0.8687\n",
      "Epoch 7: val_loss did not improve from 0.31728\n",
      "157/157 [==============================] - 12s 76ms/step - loss: 0.2767 - acc: 0.8687 - val_loss: 0.6052 - val_acc: 0.7742 - lr: 1.0000e-04\n",
      "Epoch 8/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2604 - acc: 0.8742\n",
      "Epoch 8: val_loss did not improve from 0.31728\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 0.2604 - acc: 0.8742 - val_loss: 0.3296 - val_acc: 0.7882 - lr: 1.0000e-04\n",
      "Epoch 9/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2459 - acc: 0.8782\n",
      "Epoch 9: val_loss did not improve from 0.31728\n",
      "157/157 [==============================] - 11s 68ms/step - loss: 0.2459 - acc: 0.8782 - val_loss: 0.3179 - val_acc: 0.7990 - lr: 1.0000e-04\n",
      "Epoch 10/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2355 - acc: 0.8816\n",
      "Epoch 10: val_loss improved from 0.31728 to 0.30660, saving model to /content/drive/MyDrive/Colab Notebooks/files/non-aug/unet-non-aug.h5\n",
      "157/157 [==============================] - 16s 102ms/step - loss: 0.2355 - acc: 0.8816 - val_loss: 0.3066 - val_acc: 0.8001 - lr: 1.0000e-04\n",
      "Epoch 11/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2254 - acc: 0.8841\n",
      "Epoch 11: val_loss improved from 0.30660 to 0.30044, saving model to /content/drive/MyDrive/Colab Notebooks/files/non-aug/unet-non-aug.h5\n",
      "157/157 [==============================] - 14s 91ms/step - loss: 0.2254 - acc: 0.8841 - val_loss: 0.3004 - val_acc: 0.8027 - lr: 1.0000e-04\n",
      "Epoch 12/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2164 - acc: 0.8877\n",
      "Epoch 12: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 11s 70ms/step - loss: 0.2164 - acc: 0.8877 - val_loss: 0.3032 - val_acc: 0.8036 - lr: 1.0000e-04\n",
      "Epoch 13/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2077 - acc: 0.8919\n",
      "Epoch 13: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 0.2077 - acc: 0.8919 - val_loss: 0.3057 - val_acc: 0.8014 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2005 - acc: 0.8946\n",
      "Epoch 14: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 11s 69ms/step - loss: 0.2005 - acc: 0.8946 - val_loss: 0.3020 - val_acc: 0.8023 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1963 - acc: 0.8968\n",
      "Epoch 15: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.1963 - acc: 0.8968 - val_loss: 0.3257 - val_acc: 0.7882 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1863 - acc: 0.9017\n",
      "Epoch 16: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.1863 - acc: 0.9017 - val_loss: 0.3266 - val_acc: 0.7986 - lr: 1.0000e-05\n",
      "Epoch 17/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1749 - acc: 0.9081\n",
      "Epoch 17: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 11s 70ms/step - loss: 0.1749 - acc: 0.9081 - val_loss: 0.3428 - val_acc: 0.7914 - lr: 1.0000e-05\n",
      "Epoch 18/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1680 - acc: 0.9116\n",
      "Epoch 18: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 11s 69ms/step - loss: 0.1680 - acc: 0.9116 - val_loss: 0.3497 - val_acc: 0.7882 - lr: 1.0000e-05\n",
      "Epoch 19/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1617 - acc: 0.9148\n",
      "Epoch 19: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 11s 69ms/step - loss: 0.1617 - acc: 0.9148 - val_loss: 0.3531 - val_acc: 0.7869 - lr: 1.0000e-05\n",
      "Epoch 20/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1520 - acc: 0.9196\n",
      "Epoch 20: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 12s 73ms/step - loss: 0.1520 - acc: 0.9196 - val_loss: 0.3465 - val_acc: 0.7885 - lr: 1.0000e-06\n",
      "Epoch 21/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1505 - acc: 0.9206\n",
      "Epoch 21: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 11s 69ms/step - loss: 0.1505 - acc: 0.9206 - val_loss: 0.3500 - val_acc: 0.7868 - lr: 1.0000e-06\n",
      "Epoch 22/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1494 - acc: 0.9213\n",
      "Epoch 22: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.1494 - acc: 0.9213 - val_loss: 0.3537 - val_acc: 0.7853 - lr: 1.0000e-06\n",
      "Epoch 23/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1485 - acc: 0.9218\n",
      "Epoch 23: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 0.1485 - acc: 0.9218 - val_loss: 0.3563 - val_acc: 0.7844 - lr: 1.0000e-06\n",
      "Epoch 24/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1473 - acc: 0.9225\n",
      "Epoch 24: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 12s 75ms/step - loss: 0.1473 - acc: 0.9225 - val_loss: 0.3557 - val_acc: 0.7848 - lr: 1.0000e-07\n",
      "Epoch 25/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1472 - acc: 0.9226\n",
      "Epoch 25: val_loss did not improve from 0.30044\n",
      "157/157 [==============================] - 11s 70ms/step - loss: 0.1472 - acc: 0.9226 - val_loss: 0.3557 - val_acc: 0.7849 - lr: 1.0000e-07\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e11a5caa380>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  }
 ]
}
